{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nlplab/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "#import wget\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import argparse\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from functools import partial\n",
    "import re\n",
    "from  tqdm import tqdm\n",
    "import torch\n",
    "nltk.download('punkt')\n",
    "from src.dataset_classes import DatasetObject,Features,SquadQuestionGenerationDataset\n",
    "from src.utils import answerGeneratorDataset,questionGeneratorDataset,buildFact,setuptokenizer,pad_seq,SmartCollator\n",
    "from dataclasses import dataclass, field\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlplab/anaconda3/envs/development/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_base = 't5-base'\n",
    "tokenizer = setuptokenizer(model_base=model_base,\n",
    "                           special_tokens=['<section>','</section>'\n",
    "                                           ,'<generate_questions>',\n",
    "                                           '<generate_answers>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SquadQuestionGenerationDataset(tokenizer,nb_records=1)\n",
    "dataset.change_data_mode(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_utils import model_init\n",
    "\n",
    "trained_weights = torch.load('../trained_models/t5_base_model_1/checkpoint-18000/pytorch_model.bin')\n",
    "\n",
    "generator = model_init(model_base=model_base,vocab_size=len(tokenizer))\n",
    "generator.load_state_dict(trained_weights)\n",
    "device = generator.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "import wikipedia\n",
    "def factgenerator(document,n):\n",
    "    return list(ngrams(sent_tokenize(document.strip()),n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_too = True\n",
    "sampling_helper = {} if not sample_too else dict(top_k=30, top_p=0.95,)\n",
    "max_length=250\n",
    "length_penalty=2.6\n",
    "beam_size=4\n",
    "repetition_penalty=1.56\n",
    "return_top_beams= beam_size if not sample_too else 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = wikipedia.summary('Afrobeat')\n",
    "n=4\n",
    "facts = [' '.join(s).replace('\\n','').strip() for s in factgenerator(article.replace('.T','. T'),n=n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Afrobeat is a Nigerian music genre that involves the combination of West African musical styles (such as traditional Yoruba music and highlife) and American funk, jazz, and soul influences, with a focus on chanted vocals, complex intersecting rhythms, and percussion. The style was pioneered in the 1960s by Nigerian multi-instrumentalist and bandleader Fela Kuti, who is responsible for popularizing the style both within and outside Nigeria. Distinct from Afrobeat is Afrobeats – a sound originating in West Africa in the 21st century, one that takes in diverse influences and is an eclectic combination of genres such as hip hop, house, jùjú, ndombolo, R&B and soca. The two genres, though often conflated, are not the same.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  mosestokenizer.detokenizer import MosesDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = MosesDetokenizer('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'White is an achromatic color, a color without hue.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize('White is an achromatic color , a color without hue .'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= set()\n",
    "b= set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, None]\n"
     ]
    }
   ],
   "source": [
    "d = {'alice': 18, 'bob': 24, 'carl': 32}\n",
    "keys = ['carl', 'bobs']\n",
    "result = list(map(d.get, keys))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.add('Hello')\n",
    "b.add('World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, World'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(b.union(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/nlplab/projects/question_generation/notebook/inference_q2.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blaith_server/home/nlplab/projects/question_generation/notebook/inference_q2.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m task_id \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blaith_server/home/nlplab/projects/question_generation/notebook/inference_q2.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m target_fact \u001b[39m=\u001b[39m facts[\u001b[39m1\u001b[39;49m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blaith_server/home/nlplab/projects/question_generation/notebook/inference_q2.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#'Table 1 Chemical combination rule for working with N2 gas: item[COA]. volume[32m3].  ratio[0.06].  '\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blaith_server/home/nlplab/projects/question_generation/notebook/inference_q2.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#facts[11]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blaith_server/home/nlplab/projects/question_generation/notebook/inference_q2.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blaith_server/home/nlplab/projects/question_generation/notebook/inference_q2.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#' item[COA], volume[32m3],  ratio[0.06]  Table 1: Chemical combination rule for working with N2 gas.'\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blaith_server/home/nlplab/projects/question_generation/notebook/inference_q2.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m data \u001b[39m=\u001b[39m DatasetObject(task\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m<generate_questions> \u001b[39m\u001b[39m'\u001b[39m, question\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blaith_server/home/nlplab/projects/question_generation/notebook/inference_q2.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m                      context\u001b[39m=\u001b[39mtarget_fact, fact\u001b[39m=\u001b[39mtarget_fact,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blaith_server/home/nlplab/projects/question_generation/notebook/inference_q2.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m                      answer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blaith_server/home/nlplab/projects/question_generation/notebook/inference_q2.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m                      answer_sentence\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blaith_server/home/nlplab/projects/question_generation/notebook/inference_q2.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m                      task_id\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "task_id = 0\n",
    "target_fact = facts[0]\n",
    "#'Table 1 Chemical combination rule for working with N2 gas: item[COA]. volume[32m3].  ratio[0.06].  '\n",
    "#facts[11]\n",
    "\n",
    "#' item[COA], volume[32m3],  ratio[0.06]  Table 1: Chemical combination rule for working with N2 gas.'\n",
    "data = DatasetObject(task='<generate_questions> ', question='',\n",
    "                     context=target_fact, fact=target_fact,\n",
    "                     answer='',\n",
    "                     answer_sentence='',\n",
    "                     task_id=\"\")\n",
    "\n",
    "batch = dataset.procesTexts(data)\n",
    "\n",
    "b_input_ids = batch.input_ids.view(1, -1).to(device)\n",
    "b_input_mask = batch.attention_mask.view(1, -1).to(device)\n",
    "\n",
    "sample_too = True\n",
    "sampling_helper = {} if not sample_too else dict(top_k=25, top_p=0.95,)\n",
    "return_top_beams = beam_size if not sample_too else 25\n",
    "# seed_everything(2982)\n",
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    sample_outputs = generator.generate(input_ids=b_input_ids,  **sampling_helper,\n",
    "                                        attention_mask=b_input_mask,\n",
    "                                        num_beams=beam_size,\n",
    "                                        repetition_penalty=repetition_penalty,\n",
    "                                        length_penalty=length_penalty,\n",
    "                                        early_stopping=False,\n",
    "                                        use_cache=True,\n",
    "                                        max_length=max_length,\n",
    "                                        no_repeat_ngram_size=2,\n",
    "                                        num_return_sequences=return_top_beams,\n",
    "                                        do_sample=sample_too,\n",
    "                                        eos_token_id=dataset.tokenizer.eos_token_id,)\n",
    "oop = [dataset.tokenizer.decode(sample_outputs[idx],\n",
    "                                skip_special_tokens=True,\n",
    "                                clean_up_tokenization_spaces=True) for idx in range(return_top_beams)]\n",
    "\n",
    "print(f'Article Section: {data.context}')\n",
    "print('Questions Generated')\n",
    "oop = set(oop)\n",
    "for q in oop:\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the name of the pancake that is made with buttermilk in place of eggs?\n",
      "What is the name of the type of pancake made with buttermilk in place of eggs?\n",
      "What is the pancake with buttermilk in place of or in addition to milk known as in Scotland and the US?\n",
      "What is the name of the pancake that is made with buttermilk in place of eggs when it is used in addition to milk?\n",
      "What is the name of the pancake that is used in place of buttermilk in addition to milk?\n",
      "What is the name of the pancake that is used in place of buttermilk in addition to milk?\n",
      "What is the name of the type of pancake that is made with buttermilk in place of eggs when it is used in addition to milk?\n",
      "What is the name of the pancake that is used in place of buttermilk when it is not used?\n",
      "What type of pancake can be used in place of buttermilk to make it tart?\n",
      "What is a type of buckwheat pancake that can be used in place of buttermilk or in addition to milk?\n",
      "What is the name of the pancake that is used when buttermilk is not used in place of or in addition to milk?\n",
      "What is the pancake called when buttermilk is used in place of or in addition to milk, it develops a tart flavor and becomes known as?\n",
      "What is used in place of buttermilk in the pancake batter to make it tart?\n",
      "What is used in place of buttermilk in the pancake batter to make it tart?\n",
      "What is the name of the pancake that is made with buttermilk in place of eggs when it is used in addition to milk?\n",
      "What type of pancake can be used in place of buttermilk to make it tart?\n",
      "What type of pancake can be used in place of buttermilk?\n",
      "What type of pancake can be used in place of buttermilk when it is not used to make it tart?\n",
      "What type of pancake is made when buttermilk is used in place of or in addition to milk?\n",
      "What is used in place of buttermilk in the pancake batter to make it tart?\n",
      "What type of pancake is used in place of buttermilk when it comes to making it easier to make?\n",
      "What is the name of the pancake that is used in place of buttermilk in addition to milk?\n",
      "What is the name of the type of pancake that is used in place of buttermilk?\n",
      "What is a type of buckwheat pancake that is used in place of buttermilk in order to make it tart?\n",
      "What is the name of the pancake that is used in place of buttermilk in addition to milk?\n"
     ]
    }
   ],
   "source": [
    "for q in oop:\n",
    "    print(q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('development')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "473435c5caf2da67d3d84349b3ab99ae605588908510e1f3cdf041055f6c21f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
