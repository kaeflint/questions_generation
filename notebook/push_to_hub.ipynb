{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nlplab/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "#import wget\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import argparse\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from functools import partial\n",
    "import re\n",
    "from  tqdm import tqdm\n",
    "import torch\n",
    "nltk.download('punkt')\n",
    "from functools import partial\n",
    "import nltk\n",
    "from src.dataset_processor import load_all_data\n",
    "from src.utils import SmartCollator, get_args, setuptokenizer\n",
    "from src.dataset_processor import (\n",
    "    Multi_taskQuestionGenerationDataset as QuestionGenerationDataset,\n",
    ")\n",
    "from src.model_utils import CustomTrainer, get_training_arguments, model_init\n",
    "from src.config import DATASET_PATH, GenerationTasks\n",
    "from transformers.trainer_callback import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = 'facebook/bart-base'\n",
    "tokenizer = setuptokenizer(model_base=model_base,\n",
    "                           special_tokens=[\n",
    "            GenerationTasks.vanilla_question_gen,\n",
    "            GenerationTasks.context_question_gen,\n",
    "            GenerationTasks.question_paraphrase,\n",
    "            \"<section>\",\n",
    "            \"</section>\",\n",
    "        ],\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_utils import model_init\n",
    "saved_model_path = '../trained_models_mtl/bart_base_model_fp16_ga4e5/'\n",
    "#'../trained_models_mtl/bart_base_model_1/checkpoint-25524//'\n",
    "## 127620\n",
    "trained_weights = torch.load(f'{saved_model_path}checkpoint-16032/pytorch_model.bin')\n",
    "\n",
    "generator = model_init(model_base=model_base,\n",
    "                       vocab_size=len(tokenizer))\n",
    "generator.load_state_dict(trained_weights)\n",
    "device = generator.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load argparse elements\n",
    "import pickle as pk\n",
    "args = pk.load(open(f'{saved_model_path}/train_args.ap','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(model_base='facebook/bart-base', gradient_accumulation_steps=4, fp16=True, output_dir='trained_models_mtl/', run_id='bart_base_model_fp16_ga4e5', eval_steps=1000, learning_rate=4e-05, max_squad_size=80000, max_seq_len=530, evaluation_strategy='epoch', save_strategy='epoch', seed=10, lr_scheduler_type='cosine', weight_decay=0.3, warmup_ratio=0.15, num_train_epochs=5, save_total_limit=1, per_device_train_batch_size=16, per_device_eval_batch_size=16, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "train_args = TrainingArguments(push_to_hub=True,\n",
    "                               hub_model_id=\"kaejo98/bart-base-question-generation\",\n",
    "                               overwrite_output_dir=True,\n",
    "                               output_dir='trained_models/setup_1/',\n",
    "                               evaluation_strategy=args.evaluation_strategy,  # \"epoch\",\n",
    "                               save_strategy=args.save_strategy,  # 'epoch',\n",
    "                               lr_scheduler_type=args.lr_scheduler_type,\n",
    "                               learning_rate=args.learning_rate,\n",
    "                               gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
    "                               fp16=args.fp16,\n",
    "                               save_total_limit=args.save_total_limit,\n",
    "                               weight_decay=args.weight_decay,\n",
    "                               warmup_ratio=args.warmup_ratio,\n",
    "                               num_train_epochs=args.num_train_epochs,\n",
    "                               per_device_train_batch_size=args.per_device_train_batch_size,\n",
    "                               per_device_eval_batch_size=args.per_device_train_batch_size,\n",
    "                               disable_tqdm=not args.verbose,\n",
    "                               eval_steps=args.eval_steps,\n",
    "                               save_steps=args.eval_steps,\n",
    "                               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlplab/anaconda3/envs/development/lib/python3.9/site-packages/huggingface_hub/repository.py:705: FutureWarning: Creating a repository through 'clone_from' is deprecated and will be removed in v0.11.\n",
      "  warnings.warn(\n",
      "Cloning https://huggingface.co/kaejo98/bart-base-question-generation into local empty directory.\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(generator,train_args,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.load_state_dict(trained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to trained_models/setup_1/\n",
      "Configuration saved in trained_models/setup_1/config.json\n",
      "Model weights saved in trained_models/setup_1/pytorch_model.bin\n",
      "tokenizer config file saved in trained_models/setup_1/tokenizer_config.json\n",
      "Special tokens file saved in trained_models/setup_1/special_tokens_map.json\n",
      "added tokens file saved in trained_models/setup_1/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a34a2fb2484e89a85f08591bd01fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 32.0k/532M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0e14b9cb964ff9a3daee514ac5abf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file training_args.bin: 100%|##########| 3.37k/3.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: Scanning LFS files for validity, may be slow...        \n",
      "remote: LFS file scan complete.        \n",
      "To https://huggingface.co/kaejo98/bart-base-question-generation\n",
      "   ed70c2b..d7a5564  main -> main\n",
      "\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Sequence-to-sequence Language Modeling', 'type': 'text2text-generation'}}\n",
      "To https://huggingface.co/kaejo98/bart-base-question-generation\n",
      "   d7a5564..5307375  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/kaejo98/bart-base-question-generation/commit/d7a556421c97965c19056551d7b7cc2ca7e41d77'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(\"New questions generation model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing files:  ['../curated_data/drop_train.csv', '../curated_data/squad_train.csv', '../curated_data/rope_train.csv', '../curated_data/extra_data_train.csv', '../curated_data/sci_train.csv']\n",
      "processing files:  ['../curated_data/squad_dev.csv', '../curated_data/drop_dev.csv', '../curated_data/rope_dev.csv', '../curated_data/sci_dev.csv']\n",
      "processing files:  ['../curated_data/sci_test.csv']\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = '../curated_data/'\n",
    "train_data_packet = load_all_data(DATASET_PATH, mode=\"train\")\n",
    "test_data_packet = load_all_data(DATASET_PATH, mode=\"dev\")+load_all_data(DATASET_PATH, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21734"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_packet)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n",
      "Your token has been saved to /home/nlplab/.huggingface/token\n"
     ]
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3e-4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('development')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 13 2022, 21:15:33) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "473435c5caf2da67d3d84349b3ab99ae605588908510e1f3cdf041055f6c21f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
