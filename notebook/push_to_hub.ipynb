{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nlplab/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "#import wget\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import argparse\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from functools import partial\n",
    "import re\n",
    "from  tqdm import tqdm\n",
    "import torch\n",
    "nltk.download('punkt')\n",
    "from src.dataset_classes import DatasetObject,Features,SquadQuestionGenerationDataset\n",
    "from src.utils import answerGeneratorDataset,questionGeneratorDataset,buildFact,setuptokenizer,pad_seq,SmartCollator\n",
    "from dataclasses import dataclass, field\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = 'facebook/bart-base'\n",
    "tokenizer = setuptokenizer(model_base=model_base,\n",
    "                           special_tokens=['<section>','</section>'\n",
    "                                           ,'<generate_questions>',\n",
    "                                           '<generate_answers>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_utils import model_init\n",
    "# ../trained_models/t5_base_model_1/checkpoint-18000/pytorch_model.bin\n",
    "trained_weights = torch.load('../trained_models/bart_base_model_1/checkpoint-6000/pytorch_model.bin')\n",
    "\n",
    "generator = model_init(model_base=model_base,vocab_size=len(tokenizer))\n",
    "generator.load_state_dict(trained_weights)\n",
    "device = generator.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.load_state_dict(trained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments,Trainer\n",
    "train_args = TrainingArguments(overwrite_output_dir=True, output_dir='trained_models/setup_1/',\n",
    "                               evaluation_strategy='steps',\n",
    "                               lr_scheduler_type='cosine',\n",
    "                               adafactor=False,\n",
    "                               load_best_model_at_end=True,\n",
    "                               save_total_limit=1,\n",
    "                               weight_decay=0.3,\n",
    "                               warmup_ratio=0.35,\n",
    "                               num_train_epochs=5,\n",
    "                               per_device_train_batch_size=16,\n",
    "                               push_to_hub=True,\n",
    "                               hub_model_id=\"kaejo98/bart-base_question_generation\",\n",
    "                               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/kaejo98/bart-base_question_generation into local empty directory.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(generator,train_args,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to trained_models/setup_1/\n",
      "Configuration saved in trained_models/setup_1/config.json\n",
      "Model weights saved in trained_models/setup_1/pytorch_model.bin\n",
      "tokenizer config file saved in trained_models/setup_1/tokenizer_config.json\n",
      "Special tokens file saved in trained_models/setup_1/special_tokens_map.json\n",
      "added tokens file saved in trained_models/setup_1/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c90bedc74ee44e1890fecdc2d327b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 32.0k/532M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68cfda6288c241c5965229cb52b28266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file training_args.bin: 100%|##########| 3.37k/3.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: Scanning LFS files for validity, may be slow...        \n",
      "remote: LFS file scan complete.        \n",
      "To https://huggingface.co/kaejo98/bart-base_question_generation\n",
      "   7995090..9bc25ab  main -> main\n",
      "\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Sequence-to-sequence Language Modeling', 'type': 'text2text-generation'}}\n",
      "To https://huggingface.co/kaejo98/bart-base_question_generation\n",
      "   9bc25ab..658cc99  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/kaejo98/bart-base_question_generation/commit/9bc25ab53ff6766f2b2554d0923bda2411228855'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(\"New questions generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n",
      "Your token has been saved to /home/nlplab/.huggingface/token\n"
     ]
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('development')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "473435c5caf2da67d3d84349b3ab99ae605588908510e1f3cdf041055f6c21f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
