{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nlplab/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "#import wget\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import argparse\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from functools import partial\n",
    "import re\n",
    "from  tqdm import tqdm\n",
    "import torch\n",
    "nltk.download('punkt')\n",
    "from functools import partial\n",
    "import nltk\n",
    "from src.dataset_processor import load_all_data\n",
    "from src.utils import SmartCollator, get_args, setuptokenizer\n",
    "from src.dataset_processor import (\n",
    "    Multi_taskQuestionGenerationDataset as QuestionGenerationDataset,\n",
    ")\n",
    "from src.model_utils import CustomTrainer, get_training_arguments, model_init\n",
    "from src.config import DATASET_PATH, GenerationTasks\n",
    "from transformers.trainer_callback import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = 'facebook/bart-base'\n",
    "tokenizer = setuptokenizer(model_base=model_base,\n",
    "                           special_tokens=[\n",
    "            GenerationTasks.vanilla_question_gen,\n",
    "            GenerationTasks.context_question_gen,\n",
    "            GenerationTasks.question_paraphrase,\n",
    "            \"<section>\",\n",
    "            \"</section>\",\n",
    "        ],\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_utils import model_init\n",
    "saved_model_path = '../trained_models_mtl/bart_base_model_1/'\n",
    "#'../trained_models_mtl/bart_base_model_1/checkpoint-25524//'\n",
    "trained_weights = torch.load(f'{saved_model_path}checkpoint-127620/pytorch_model.bin')\n",
    "\n",
    "generator = model_init(model_base=model_base,\n",
    "                       vocab_size=len(tokenizer))\n",
    "generator.load_state_dict(trained_weights)\n",
    "device = generator.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load argparse elements\n",
    "import pickle as pk\n",
    "args = pk.load(open(f'{saved_model_path}/train_args.ap','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(model_base='facebook/bart-base', output_dir='trained_models_mtl/', run_id='bart_base_model_1', eval_steps=1000, learning_rate=3e-05, max_squad_size=80000, max_seq_len=512, evaluation_strategy='epoch', save_strategy='epoch', seed=10, lr_scheduler_type='cosine', weight_decay=0.3, warmup_ratio=0.25, num_train_epochs=5, save_total_limit=1, per_device_train_batch_size=16, per_device_eval_batch_size=16, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "train_args = TrainingArguments(push_to_hub=True,\n",
    "                               hub_model_id=\"kaejo98/bart-base_question_generation\",\n",
    "                               overwrite_output_dir=True,\n",
    "                               output_dir='trained_models/setup_1/',\n",
    "                               evaluation_strategy=args.evaluation_strategy,  # \"epoch\",\n",
    "                               save_strategy=args.save_strategy,  # 'epoch',\n",
    "                               lr_scheduler_type=args.lr_scheduler_type,\n",
    "                               learning_rate=args.learning_rate,\n",
    "\n",
    "                               save_total_limit=args.save_total_limit,\n",
    "                               weight_decay=args.weight_decay,\n",
    "                               warmup_ratio=args.warmup_ratio,\n",
    "                               num_train_epochs=args.num_train_epochs,\n",
    "                               per_device_train_batch_size=args.per_device_train_batch_size,\n",
    "                               per_device_eval_batch_size=args.per_device_train_batch_size,\n",
    "                               disable_tqdm=not args.verbose,\n",
    "                               eval_steps=args.eval_steps,\n",
    "                               save_steps=args.eval_steps,\n",
    "                               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/kaejo98/bart-base_question_generation into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f87a8ee1034f128de01493d8fb3753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file pytorch_model.bin:   0%|          | 15.4k/532M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f447959b7b1441da4448bdb9bb7fa9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file training_args.bin: 100%|##########| 3.37k/3.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73dec81577c24cea9d823b3a52913683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file training_args.bin:  30%|##9       | 1.00k/3.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68309712699d4ce7a4923aad83793fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file pytorch_model.bin:   0%|          | 1.00k/532M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(generator,train_args,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.load_state_dict(trained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to trained_models/setup_1/\n",
      "Configuration saved in trained_models/setup_1/config.json\n",
      "Model weights saved in trained_models/setup_1/pytorch_model.bin\n",
      "tokenizer config file saved in trained_models/setup_1/tokenizer_config.json\n",
      "Special tokens file saved in trained_models/setup_1/special_tokens_map.json\n",
      "added tokens file saved in trained_models/setup_1/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddeb14e099c412594a6d226b6ad30ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 32.0k/532M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b86bd2a5e6412fae9d8e5298d6ef41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file training_args.bin: 100%|##########| 3.37k/3.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: Scanning LFS files for validity, may be slow...        \n",
      "remote: LFS file scan complete.        \n",
      "To https://huggingface.co/kaejo98/bart-base_question_generation\n",
      "   120358f..dc51d72  main -> main\n",
      "\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Sequence-to-sequence Language Modeling', 'type': 'text2text-generation'}}\n",
      "To https://huggingface.co/kaejo98/bart-base_question_generation\n",
      "   dc51d72..ba60400  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/kaejo98/bart-base_question_generation/commit/dc51d723a747e58c04767205045c1b85cb2e9bc9'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(\"New questions generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing files:  ['../curated_data/drop_train.csv', '../curated_data/squad_train.csv', '../curated_data/rope_train.csv', '../curated_data/extra_data_train.csv', '../curated_data/sci_train.csv']\n",
      "processing files:  ['../curated_data/squad_dev.csv', '../curated_data/drop_dev.csv', '../curated_data/rope_dev.csv', '../curated_data/sci_dev.csv']\n",
      "processing files:  ['../curated_data/sci_test.csv']\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = '../curated_data/'\n",
    "train_data_packet = load_all_data(DATASET_PATH, mode=\"train\")\n",
    "test_data_packet = load_all_data(DATASET_PATH, mode=\"dev\")+load_all_data(DATASET_PATH, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21734"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_packet)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n",
      "Your token has been saved to /home/nlplab/.huggingface/token\n"
     ]
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3e-4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('development')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "473435c5caf2da67d3d84349b3ab99ae605588908510e1f3cdf041055f6c21f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
