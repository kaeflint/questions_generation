{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset adversarial_qa (/home/nlplab/.cache/huggingface/datasets/adversarial_qa/adversarialQA/1.0.0/92356be07b087c5c6a543138757828b8d61ca34de8a87807d40bbc0e6c68f04b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172a493b8d29495bbc2b09db6852c2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset adversarial_qa (/home/nlplab/.cache/huggingface/datasets/adversarial_qa/dbidaf/1.0.0/92356be07b087c5c6a543138757828b8d61ca34de8a87807d40bbc0e6c68f04b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82fca5076e4946169aaabad1509cb9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset adversarial_qa (/home/nlplab/.cache/huggingface/datasets/adversarial_qa/dbert/1.0.0/92356be07b087c5c6a543138757828b8d61ca34de8a87807d40bbc0e6c68f04b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c23f4de8cf54c48b7d2379d73e41e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset adversarial_qa (/home/nlplab/.cache/huggingface/datasets/adversarial_qa/droberta/1.0.0/92356be07b087c5c6a543138757828b8d61ca34de8a87807d40bbc0e6c68f04b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229e3862683342d6af904e5b746ac2a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "#['adversarialQA', 'dbidaf', 'dbert', 'droberta']\n",
    "dataset1 = load_dataset(\"adversarial_qa\",'adversarialQA')\n",
    "dataset2 = load_dataset(\"adversarial_qa\",'dbidaf')\n",
    "dataset3 = load_dataset(\"adversarial_qa\",'dbert')\n",
    "dataset4 = load_dataset(\"adversarial_qa\",'droberta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = [dataset1['train'],dataset2['train'],dataset3['train'],dataset4['train']]\n",
    "test_dataset = [dataset1['test'],dataset2['test'],dataset3['test'],dataset4['test']]\n",
    "val_dataset = [dataset1['validation'],dataset2['validation'],\n",
    "               dataset3['validation'],dataset4['validation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '7ba1e8f4261d3170fcf42e84a81dd749116fae95',\n",
       " 'title': 'Brain',\n",
       " 'context': 'Another approach to brain function is to examine the consequences of damage to specific brain areas. Even though it is protected by the skull and meninges, surrounded by cerebrospinal fluid, and isolated from the bloodstream by the blood–brain barrier, the delicate nature of the brain makes it vulnerable to numerous diseases and several types of damage. In humans, the effects of strokes and other types of brain damage have been a key source of information about brain function. Because there is no ability to experimentally control the nature of the damage, however, this information is often difficult to interpret. In animal studies, most commonly involving rats, it is possible to use electrodes or locally injected chemicals to produce precise patterns of damage and then examine the consequences for behavior.',\n",
       " 'question': 'What sare the benifts of the blood brain barrir?',\n",
       " 'answers': {'text': ['isolated from the bloodstream'], 'answer_start': [195]},\n",
       " 'metadata': {'split': 'train', 'model_in_the_loop': 'Combined'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import random\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset_processor import QuestionGenerationData\n",
    "from src.config import GenerationTasks\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.util import ngrams\n",
    "def selectContext(articles, answer_index,n=4):\n",
    "    vals = list(ngrams(range(len(articles)),n))\n",
    "    for l in vals:\n",
    "        if answer_index in l:\n",
    "            return l\n",
    "\n",
    "def get_span_sentence(span_answer,passage,n=4):\n",
    "    answer = span_answer.strip()\n",
    "    context = passage.strip()\n",
    "    contexts = sent_tokenize(context)\n",
    "    \n",
    "    answer_index = [idx for idx, s in enumerate(contexts) if answer in s]\n",
    "    answer_sentences = [s for idx, s in enumerate(contexts) if answer in s]\n",
    "\n",
    "    if len(contexts) < 5 and len(answer_index) >0:\n",
    "        return passage.strip(), \" \".join(answer_sentences)\n",
    "    if len(answer_index) < 1:\n",
    "        return None\n",
    "    else:\n",
    "        if len(answer_index)==1:\n",
    "            selected_context_idxs = selectContext(contexts, answer_index, n=n)\n",
    "            if selected_context_idxs is not None:\n",
    "                answer_context = ' '.join([contexts[sid] for sid in selected_context_idxs])\n",
    "            else:\n",
    "                answer_context = passage.strip()\n",
    "        else:\n",
    "            answer_context =  \" \".join(answer_sentences)\n",
    "    return answer_context,  \" \".join(answer_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_adversarial_qa(data_pack):\n",
    "    dataset =[]\n",
    "    for pack in data_pack:\n",
    "        for item in pack:\n",
    "            context= item['context']\n",
    "            question = item['question']\n",
    "            answer = item['answers']\n",
    "            if len(answer['text'])>0:\n",
    "                answer_text = answer['text'][0]\n",
    "                answer_start = answer['answer_start'][0]\n",
    "                \n",
    "                obj = get_span_sentence(answer_text,context,n=4)\n",
    "                \n",
    "                question_based_on_context = QuestionGenerationData(task=GenerationTasks.context_question_gen,\n",
    "                                            input_text= context.strip(),\n",
    "                                            output_text=question.strip(),\n",
    "                                            contextual_text= answer_text.strip())\n",
    "                dataset.append(question_based_on_context)\n",
    "                \n",
    "                if obj is not None:\n",
    "                        #print(answer_sentence)\n",
    "                        fact, answer_sentence = obj\n",
    "\n",
    "                        question_based_without_context = QuestionGenerationData(task=GenerationTasks.vanilla_question_gen, \n",
    "                                                                                input_text= fact, output_text=question,\n",
    "                                                                                contextual_text= answer_sentence.strip())\n",
    "                        dataset.append(question_based_without_context)\n",
    "            else:\n",
    "                question_based_on_context = QuestionGenerationData(task=GenerationTasks.vanilla_question_gen,\n",
    "                                            input_text= context.strip(),\n",
    "                                            output_text=question.strip(),\n",
    "                                            contextual_text= \"\")\n",
    "                dataset.append(question_based_on_context)\n",
    "    return dataset         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'fa2b68a340fa4292aa491e02a1498e26798c8402',\n",
       " 'title': 'Civil_disobedience',\n",
       " 'context': 'There have been debates as to whether civil disobedience must necessarily be non-violent. Black\\'s Law Dictionary includes non-violence in its definition of civil disobedience. Christian Bay\\'s encyclopedia article states that civil disobedience requires \"carefully chosen and legitimate means,\" but holds that they do not have to be non-violent. It has been argued that, while both civil disobedience and civil rebellion are justified by appeal to constitutional defects, rebellion is much more destructive; therefore, the defects justifying rebellion must be much more serious than those justifying disobedience, and if one cannot justify civil rebellion, then one cannot justify a civil disobedients\\' use of force and violence and refusal to submit to arrest. Civil disobedients\\' refraining from violence is also said to help preserve society\\'s tolerance of civil disobedience.',\n",
       " 'question': 'What encyclopedia article is referenced in this article?',\n",
       " 'answers': {'text': [], 'answer_start': []},\n",
       " 'metadata': {'split': 'test', 'model_in_the_loop': 'Combined'}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_extracted = process_adversarial_qa(train_dataset) + process_adversarial_qa(test_dataset)\n",
    "val_dataset_extracted = process_adversarial_qa(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset_extracted = process_adversarial_qa(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc=[v for v in train_dataset_extracted if v.task==GenerationTasks.vanilla_question_gen]\n",
    "cw=[v for v in train_dataset_extracted if v.task==GenerationTasks.context_question_gen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119652, 6000)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset_extracted),len(test_dataset_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclass_csv import DataclassReader, dateformat,DataclassWriter\n",
    "\n",
    "with open(\"../curated_data/adversarial_qa_train.csv\", \"w\",encoding='utf-8') as f:\n",
    "    w = DataclassWriter(f, train_dataset_extracted, QuestionGenerationData)\n",
    "    w.write()\n",
    "\n",
    "with open(\"../curated_data/adversarial_qa_dev.csv\", \"w\",encoding='utf-8') as f:\n",
    "    w = DataclassWriter(f, val_dataset_extracted, QuestionGenerationData)\n",
    "    w.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "#['new_wiki', 'nyt', 'reddit', 'amazon']\n",
    "dataset_squad_shift_wiki = load_dataset(\"squadshifts\",'new_wiki')\n",
    "dataset_squad_shift_nyt = load_dataset(\"squadshifts\",'nyt')\n",
    "dataset_squad_shift_reddit = load_dataset(\"squadshifts\",'reddit')\n",
    "dataset_squad_shift_amazon = load_dataset(\"squadshifts\",'amazon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5d700715c8e4820a9b66acd2',\n",
       " 'title': 'https://www.nytimes.com/2015/02/05/us/more-college-freshmen-report-having-felt-depressed.html',\n",
       " 'context': 'Suzanne Ciechalski, a freshman at St. John’s University in Queens, said technology that might appear social in nature could in fact lead to stress and feelings of depression. “I feel like people spend a lot of time on social networks trying to create this picture of who they want to be,” Ms. Ciechalski said. “Maintaining that takes a lot of effort. I feel like being a teenager or young adult, the pressure to try and make people see you’re the best is really high.” Contrary to some reports of high rates of drinking among high school students, the survey found a continued decline in college freshmen reporting those behaviors. About one-third said they had drunk beer, wine or hard alcohol at least occasionally in the past year, compared with almost half just 10 years ago. Fewer than one in 50 students reported smoking cigarettes.',\n",
       " 'question': 'What do people do on social networks?',\n",
       " 'answers': {'text': ['create this picture of who they want to be',\n",
       "   'create this picture of who they want to be,',\n",
       "   'trying to create this picture of who they want to be'],\n",
       "  'answer_start': [244, 244, 234]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_squad_shift_nyt['test'][200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2c920027a04058b7a770cba192d056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.70k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26dbb996bfcd4ef8bf08ad0b1dcfc688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/6.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25392ed8f134219bf8a35f6a721773b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.82k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: simple_questions_v2/annotated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset simple_questions_v2/annotated to /home/nlplab/.cache/huggingface/datasets/simple_questions_v2/annotated/1.0.0/d4192b0a3f18df90a99f9f56987766d28ae2e48bc479053894efadaf20b6e935...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be411830fc2d41c289468492088cacf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/423M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916fa743f05e4b99a6beaf6c7f9f3b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/75910 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd92d156efaa440da6495b6200489185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/75910 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d9578825cc4597a662659149102920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/75910 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset simple_questions_v2 downloaded and prepared to /home/nlplab/.cache/huggingface/datasets/simple_questions_v2/annotated/1.0.0/d4192b0a3f18df90a99f9f56987766d28ae2e48bc479053894efadaf20b6e935. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40962ce89474a6c9d0fcea932162d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset = load_dataset(\"cuad\")\n",
    "dataset = load_dataset(\"simple_questions_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '10',\n",
       " 'subject_entity': 'www.freebase.com/m/02dtg',\n",
       " 'relationship': 'www.freebase.com/location/location/people_born_here',\n",
       " 'object_entity': 'www.freebase.com/m/01s8mcb',\n",
       " 'question': 'who is a musician born in detroit\\n'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_aquamuse = load_dataset(\"aquamuse\",'abstractive')\n",
    "dataset_aquamuse_ex = load_dataset(\"aquamuse\",'extractive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'where did the tv show the waltons take place',\n",
       " 'input_urls': ['https://teeveesgreatest.webs.com/apps/videos/videos/show/18885574-the-waltons-opening-and-closing-theme-1972-1981-with-snippet-',\n",
       "  'https://wikivisually.com/wiki/Ellen_Corby',\n",
       "  'https://hamaika.tv/author/admin/page/88/'],\n",
       " 'target': \"The main story is set in Walton's Mountain, a fictional town at the foot of a mountain in fictitious Jefferson County, Virginia.\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_aquamuse['train'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'who was the first woman selected in rajya sabha',\n",
       " 'input_urls': ['https://events.artculturefestival.in/2017/11/list-bharatanatyam-dancers-india?tribe_event_display=list&tribe_paged=3',\n",
       "  'https://feminisminindia.com/2018/12/05/rukmini-devi-arundale-the-dancer-who-refused-presidency-indianwomeninhistory/',\n",
       "  'https://en.wikiquote.org/wiki/Rukmini_Devi_Arundale',\n",
       "  'http://estrelitzia.eu/40166-the-video-descriptions-of-ancient-india/'],\n",
       " 'target': \"She also is the first ever woman in Indian History to be nominated as the Rajya Sabha member. She is considered the most important revivalist in the Indian classical dance form of Bharatanatyam from its original' sadhir' style, prevalent amongst the temple dancers, Devadasis, she also worked for the re-establishment of traditional Indian arts and crafts.\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_aquamuse['train'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "473435c5caf2da67d3d84349b3ab99ae605588908510e1f3cdf041055f6c21f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
